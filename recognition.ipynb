{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes in an annotation and draws the bounding box of the faces\n",
    "# this works but having the function input be the image path is not ideal\n",
    "# NO LONGER NEEDED FOR FINAL VERSION OF THE PROJECT\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def draw_bbox_on_image(image_path, ellipses):\n",
    "    with Image.open(image_path) as img:\n",
    "        for ellipse in ellipses:\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            major_axis_radius, minor_axis_radius, angle, center_x, center_y = ellipse\n",
    "\n",
    "            \n",
    "            bbox = [\n",
    "                center_x - minor_axis_radius,\n",
    "                center_y - major_axis_radius,\n",
    "                center_x + minor_axis_radius,\n",
    "                center_y + major_axis_radius\n",
    "            ]\n",
    "            \n",
    "            if angle != 0:\n",
    "                # If there is an angle, we'd have to calculate the rotated bounding box\n",
    "                # For simplicity here, we're not handling rotation. To do so would require\n",
    "                # additional calculations that take into account the angle of rotation\n",
    "                pass\n",
    "\n",
    "            # Draw the bounding box on the image\n",
    "            draw.rectangle(bbox, outline='red')\n",
    "\n",
    "        # Display the image\n",
    "        img.show()\n",
    "        # Optionally, save the image with bounding boxes\n",
    "        # img.save('annotated_image_with_bbox.jpg')\n",
    "\n",
    "# Path to your image\n",
    "# image_path = 'FDDB/originalPics/2002/07/25/big/img_722.jpg'\n",
    "image_path = 'FDDB/originalPics/2002/08/26/big/img_265.jpg'\n",
    "# '/Users/log/Github/FacialRecognition/FDDB/originalPics/2002/08/26/big/img_265.jpg'\n",
    "# Ellipse data from your previous message\n",
    "ellipses = [\n",
    "    (67.363819, 44.511485, -1.476417, 105.249970, 87.209036),\n",
    "    (41.936870, 27.064477, 1.471906, 184.070915, 129.345601),\n",
    "    (70.993052, 43.355200, 1.370217, 340.894300, 117.498951)\n",
    "]\n",
    "\n",
    "# Call the function with the path and the ellipses\n",
    "draw_bbox_on_image(image_path, ellipses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e507990d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 51\u001b[0m\n\u001b[1;32m     40\u001b[0m input_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124m2002/08/26/big/img_259\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124m4\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124m38.431040 24.917959 -1.399011 445.562600 207.431100  1\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Call the function with the input string\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mdraw_bbox_on_image_from_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m, in \u001b[0;36mdraw_bbox_on_image_from_string\u001b[0;34m(input_string)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ellipse \u001b[38;5;129;01min\u001b[39;00m ellipses:\n\u001b[1;32m     20\u001b[0m     draw \u001b[38;5;241m=\u001b[39m ImageDraw\u001b[38;5;241m.\u001b[39mDraw(img)\n\u001b[0;32m---> 21\u001b[0m     major_axis_radius, minor_axis_radius, angle, center_x, center_y \u001b[38;5;241m=\u001b[39m ellipse\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Define the bounding box around the ellipse\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     25\u001b[0m         center_x \u001b[38;5;241m-\u001b[39m minor_axis_radius,\n\u001b[1;32m     26\u001b[0m         center_y \u001b[38;5;241m-\u001b[39m major_axis_radius,\n\u001b[1;32m     27\u001b[0m         center_x \u001b[38;5;241m+\u001b[39m minor_axis_radius,\n\u001b[1;32m     28\u001b[0m         center_y \u001b[38;5;241m+\u001b[39m major_axis_radius\n\u001b[1;32m     29\u001b[0m     ]\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 0)"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def draw_bbox_on_image_from_string(input_string):\n",
    "    # Split the input string into lines\n",
    "    lines = input_string.strip().split('\\n')\n",
    "    \n",
    "    # Extract image path and number of ellipses\n",
    "    image_path = f\"FDDB/originalPics/{lines[0]}.jpg\"  # Adjust directory as needed\n",
    "    num_ellipses = int(lines[1])\n",
    "    \n",
    "    # Extract ellipse data\n",
    "    ellipses = []\n",
    "    for i in range(2, 2 + num_ellipses):\n",
    "        parts = lines[i].split()\n",
    "        ellipses.append(tuple(map(float, parts[:5])))  # Convert each part to float, ignore the last '1'\n",
    "    \n",
    "    # Process each ellipse\n",
    "    with Image.open(image_path) as img:\n",
    "        for ellipse in ellipses:\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            major_axis_radius, minor_axis_radius, angle, center_x, center_y = ellipse\n",
    "\n",
    "            # Define the bounding box around the ellipse\n",
    "            bbox = [\n",
    "                center_x - minor_axis_radius,\n",
    "                center_y - major_axis_radius,\n",
    "                center_x + minor_axis_radius,\n",
    "                center_y + major_axis_radius\n",
    "            ]\n",
    "\n",
    "            # Draw the bounding box on the image\n",
    "            draw.rectangle(bbox, outline='red')\n",
    "\n",
    "        # Display the image\n",
    "        img.show()\n",
    "        # Optionally, save the image with bounding boxes\n",
    "        # img.save('annotated_image_with_bbox.jpg')\n",
    "\n",
    "# Input string with image information\n",
    "input_string = \"\"\"\n",
    "2002/08/26/big/img_259\n",
    "4\n",
    "\n",
    "89.757378 62.540500 -1.324079 169.035200 124.661316  1\n",
    "68.182171 42.739022 1.459486 311.487300 147.333863  1\n",
    "41.468070 25.259343 1.513220 248.658500 119.605100  1\n",
    "38.431040 24.917959 -1.399011 445.562600 207.431100  1\n",
    "\"\"\"\n",
    "\n",
    "# Call the function with the input string\n",
    "draw_bbox_on_image_from_string(input_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32340f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20884cf9",
   "metadata": {},
   "source": [
    "img: define input image size\n",
    "batch: determine batch size\n",
    "epochs: define the number of training epochs. (Note: often, 3000+ are common here!)\n",
    "data: set the path to our yaml file\n",
    "cfg: specify our model configuration\n",
    "weights: specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive folder)\n",
    "name: result names\n",
    "nosave: only save the final checkpoint\n",
    "cache: cache images for faster training\n",
    "\n",
    "/Users/log/Github/FacialRecognition/face detect.v4i.yolov5pytorch\n",
    "\n",
    "python train.py --img 640 --batch 16 --epochs 100 --data \"/Users/log/Github/FacialRecognition/RoboflowDataset/data.yaml\" --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache\n",
    "\n",
    "python train.py --img 640 --batch 16 --epochs 100 --data \"/Users/log/Github/FacialRecognition/RoboflowDataset/data.yaml\" --weights yolov5s.pt --name yolov5s_results  --cache\n",
    "\n",
    "--weights yolov5s.pt\n",
    "\n",
    "\n",
    "python detect.py --weights runs/train/yolov5s_results6/weights/best.pt --img 640 --conf 0.25 --source /Users/log/Github/FacialRecognition/RoboflowDataset/test/images/0007_jpg.rf.f0380d27244af0acfffd4a1ae3a38b0e.jpg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
